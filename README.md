# Metaphor: Meta-Learning for Misinformation Detection

An outline of the argument made in this research project:

- Catastrophic forgetting/interference is a known pitfall of neural networks when the training distribution is drawn from a variety of 'tasks'. 
- In essence, training a single model for different misinformation topics falls in this category, model learns about certain 'hashtags' for example, but can be easily tricked as a result.
